{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from datasets import load_dataset\n",
    "from datasets import ClassLabel, Sequence\n",
    "from DataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      sentence_id language            intent  written   spoken         type  \\\n0               0       en          OpenArea     show     show        plain   \n1               0       en          OpenArea    photo    photo  mycloudarea   \n2               0       en          OpenArea       on       on        plain   \n3               0       en          OpenArea  mycloud  mycloud        plain   \n4               1       en          OpenArea     show     show        plain   \n...           ...      ...               ...      ...      ...          ...   \n7609         1364       en  WatchNextEpisode  another  another        plain   \n7610         1364       en  WatchNextEpisode  episode  episode        plain   \n7611         1365       en  WatchNextEpisode      one      one        plain   \n7612         1365       en  WatchNextEpisode     more     more        plain   \n7613         1365       en  WatchNextEpisode  episode  episode        plain   \n\n      token_id    token tag  \n0            0     show   O  \n1            1    photo   O  \n2            2       on   O  \n3            3  mycloud   O  \n4            0     show   O  \n...        ...      ...  ..  \n7609         0  another   O  \n7610         1  episode   O  \n7611         0      one   O  \n7612         1     more   O  \n7613         2  episode   O  \n\n[7614 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence_id</th>\n      <th>language</th>\n      <th>intent</th>\n      <th>written</th>\n      <th>spoken</th>\n      <th>type</th>\n      <th>token_id</th>\n      <th>token</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>en</td>\n      <td>OpenArea</td>\n      <td>show</td>\n      <td>show</td>\n      <td>plain</td>\n      <td>0</td>\n      <td>show</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>en</td>\n      <td>OpenArea</td>\n      <td>photo</td>\n      <td>photo</td>\n      <td>mycloudarea</td>\n      <td>1</td>\n      <td>photo</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>en</td>\n      <td>OpenArea</td>\n      <td>on</td>\n      <td>on</td>\n      <td>plain</td>\n      <td>2</td>\n      <td>on</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>en</td>\n      <td>OpenArea</td>\n      <td>mycloud</td>\n      <td>mycloud</td>\n      <td>plain</td>\n      <td>3</td>\n      <td>mycloud</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>en</td>\n      <td>OpenArea</td>\n      <td>show</td>\n      <td>show</td>\n      <td>plain</td>\n      <td>0</td>\n      <td>show</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>1364</td>\n      <td>en</td>\n      <td>WatchNextEpisode</td>\n      <td>another</td>\n      <td>another</td>\n      <td>plain</td>\n      <td>0</td>\n      <td>another</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>1364</td>\n      <td>en</td>\n      <td>WatchNextEpisode</td>\n      <td>episode</td>\n      <td>episode</td>\n      <td>plain</td>\n      <td>1</td>\n      <td>episode</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>1365</td>\n      <td>en</td>\n      <td>WatchNextEpisode</td>\n      <td>one</td>\n      <td>one</td>\n      <td>plain</td>\n      <td>0</td>\n      <td>one</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>1365</td>\n      <td>en</td>\n      <td>WatchNextEpisode</td>\n      <td>more</td>\n      <td>more</td>\n      <td>plain</td>\n      <td>1</td>\n      <td>more</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7613</th>\n      <td>1365</td>\n      <td>en</td>\n      <td>WatchNextEpisode</td>\n      <td>episode</td>\n      <td>episode</td>\n      <td>plain</td>\n      <td>2</td>\n      <td>episode</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>7614 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared = pd.read_csv('../output/prepared_data.csv')\n",
    "DataLoader(prepared, test_ratio=.1).save_to_csv('../output')\n",
    "prepared"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['token', 'tag', 'sentence_id'],\n        num_rows: 1106\n    })\n    test: Dataset({\n        features: ['token', 'tag', 'sentence_id'],\n        num_rows: 136\n    })\n    validation: Dataset({\n        features: ['token', 'tag', 'sentence_id'],\n        num_rows: 123\n    })\n    train_all: Dataset({\n        features: ['token', 'tag', 'sentence_id'],\n        num_rows: 1229\n    })\n})"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "def read_dataset_from_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    feature_tag = Sequence(ClassLabel(num_classes=3, names=list(pd.factorize(df['tag'])[1])))\n",
    "    df['tag'] = df['tag'].apply(feature_tag.feature.str2int)\n",
    "    df_text = df.groupby(['sentence_id']).agg({'token':list, 'tag':list})\n",
    "    dataset = Dataset.from_pandas(df_text)\n",
    "    dataset.features[f\"tag\"] = feature_tag\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>tag</th>\n      <th>sentence_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[i, would, like, to, listen, to, drs, four]</td>\n      <td>[O, O, O, O, O, O, B-TBNorm, I-TBNorm]</td>\n      <td>179</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[is, it, pouring]</td>\n      <td>[O, O, O]</td>\n      <td>1170</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[volume, down, please]</td>\n      <td>[O, O, O]</td>\n      <td>1097</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[give, me, some, information, about, richard, gere]</td>\n      <td>[O, O, O, O, O, O, O]</td>\n      <td>559</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[turn, on, all, my, strom, wifi, switch]</td>\n      <td>[O, O, O, O, O, O, O]</td>\n      <td>408</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[standby]</td>\n      <td>[O]</td>\n      <td>1281</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[please, start, this, show, from, the, beginning]</td>\n      <td>[O, O, O, O, O, O, O]</td>\n      <td>443</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[we, need, guest, wi, fi, now]</td>\n      <td>[O, O, O, O, O, O]</td>\n      <td>802</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[could, you, please, press, play]</td>\n      <td>[O, O, O, O, O]</td>\n      <td>814</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[show, me, live, tv, again]</td>\n      <td>[O, O, O, O, O]</td>\n      <td>106</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(datasets[\"train\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import DistilBertForTokenClassification\n",
    "pretrained_path = './pretrained/distilbert-base-uncased/'\n",
    "model = DistilBertForTokenClassification.from_pretrained(pretrained_path, num_labels=3)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(pretrained_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [[101, 2735, 2125, 2026, 1045, 8957, 102], [101, 3531, 5587, 2023, 3185, 2000, 2026, 5633, 102], [101, 2129, 2152, 2003, 1996, 4860, 1999, 9814, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, -100]]}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_all_tokens = True\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"token\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"tag\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenize_and_align_labels(datasets['train'][:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54d9f45544fc41099445eccce63c7576"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce77d77327d345909c70e4c53e2c1275"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbf4ea76bf5d4eccaba6051980869344"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8ae8e2291dc4c7ba04fd159d907ee5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='2' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/210 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-51-bf11b017405e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m )\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/opt/miniconda3/envs/postprocessor/lib/python3.8/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001B[0m\n\u001B[1;32m    938\u001B[0m                         \u001B[0mtr_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    939\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 940\u001B[0;31m                     \u001B[0mtr_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    941\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_total_flos\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloating_point_ops\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    942\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/miniconda3/envs/postprocessor/lib/python3.8/site-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtraining_step\u001B[0;34m(self, model, inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepspeed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1319\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1320\u001B[0;31m             \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1321\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1322\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/miniconda3/envs/postprocessor/lib/python3.8/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    219\u001B[0m                 \u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m                 create_graph=create_graph)\n\u001B[0;32m--> 221\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/miniconda3/envs/postprocessor/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m    128\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 130\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    131\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    132\u001B[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "batch_size = 16\n",
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "label_list = datasets[\"train\"].features[f\"tag\"].feature.names\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"exp-1\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels', 'sentence_id', 'tag', 'token'],\n        num_rows: 1106\n    })\n    test: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels', 'sentence_id', 'tag', 'token'],\n        num_rows: 136\n    })\n    validtaion: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels', 'sentence_id', 'tag', 'token'],\n        num_rows: 123\n    })\n    train_all: Dataset({\n        features: ['attention_mask', 'input_ids', 'labels', 'sentence_id', 'tag', 'token'],\n        num_rows: 1229\n    })\n})"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_dataset(trainer, data):\n",
    "    predictions, labels, _ = trainer.predict(data)\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "\n",
    "label, pred = predict_dataset(trainer, tokenized_datasets['test'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from classification_report import f1_scores, confusion_matrix\n",
    "f1_scores(pred, label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(pred, label, label_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}