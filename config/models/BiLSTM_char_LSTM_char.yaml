save_data: {*path}/example

# Prevent overwriting existing files in the folder
overwrite: True

# Corpus opts:
data:
    corpus_1:
        path_src: {*path}/data/src_train.txt
        path_tgt: {*path}/data/tgt_train.txt
        src_seq_length: 100
        tgt_seq_length: 100
        weight: 8
    corpus_2:
        path_src: {*path}/data/src_train_special.txt
        path_tgt: {*path}/data/tgt_train_special.txt
        src_seq_length: 100
        tgt_seq_length: 100
        weight: 1
    corpus_3:
        path_src: {*path}/data/src_num_seq.txt
        path_tgt: {*path}/data/tgt_num_seq.txt
        src_seq_length: 100
        tgt_seq_length: 100
        weight: 1
    valid:
        path_src: {*path}/data/src_valid.txt
        path_tgt: {*path}/data/tgt_valid.txt
        src_seq_length: 100
        tgt_seq_length: 100

# Where the vocab(s) will be written
src_vocab: {*path}/example.vocab.src
tgt_vocab: {*path}/example.vocab.tgt

# Train on a single GPU
world_size: 1
gpu_ranks: [0]


# supported types: GloVe, word2vec
word_vec_size: 100

# Where to save the checkpoints
save_model: {*path}/
save_checkpoint_steps: 10000
train_steps: 70000
valid_steps: 10000

encoder_type: brnn
decoder_type: rnn
rnn_type: LSTM
enc_layers: 2
dec_layers: 2
rnn_size: 512
learning_rate: 0.5

tensorboard: True
tensorboard_log_dir: {*path}/board
