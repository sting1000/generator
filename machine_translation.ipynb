{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = open('data/commands_source_en_70k.txt', encoding='UTF-8').read().strip().split('\\n')  \n",
    "target = open('data/commands_target_en_70k.txt', encoding='UTF-8').read().strip().split('\\n')  \n",
    "source_num = open('data/nums_source_en_10k.txt', encoding='UTF-8').read().strip().split('\\n')  \n",
    "target_num = open('data/nums_target_en_10k.txt', encoding='UTF-8').read().strip().split('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.extend(source_num)\n",
    "target.extend(target_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([!?])\", r\" \\1\", s)\n",
    "#     s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s), normalizeString(t) ]for s, t in list(zip(target, source))] \n",
    "\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 80000 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "src 6190\n",
      "tgt 16864\n",
      "['turn on blue sports twenty two', 'turn on blue sports 22']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "#     pairs = filterPairs(pairs)\n",
    "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('src', 'tgt')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=50):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=50):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 0s (- 46m 15s) (3000 4%) 3.8974\n",
      "4m 1s (- 44m 18s) (6000 8%) 2.4666\n",
      "6m 3s (- 42m 22s) (9000 12%) 1.9148\n",
      "8m 4s (- 40m 20s) (12000 16%) 1.6596\n",
      "10m 7s (- 38m 29s) (15000 20%) 1.5601\n",
      "12m 11s (- 36m 34s) (18000 25%) 1.4427\n",
      "14m 12s (- 34m 30s) (21000 29%) 1.4515\n",
      "16m 15s (- 32m 30s) (24000 33%) 1.4579\n",
      "18m 18s (- 30m 30s) (27000 37%) 1.2978\n",
      "20m 21s (- 28m 30s) (30000 41%) 1.2934\n",
      "22m 25s (- 26m 29s) (33000 45%) 1.2221\n",
      "24m 27s (- 24m 27s) (36000 50%) 1.2189\n",
      "26m 31s (- 22m 27s) (39000 54%) 1.1994\n",
      "28m 37s (- 20m 26s) (42000 58%) 1.1873\n",
      "30m 41s (- 18m 25s) (45000 62%) 1.1600\n",
      "32m 42s (- 16m 21s) (48000 66%) 1.2238\n",
      "34m 48s (- 14m 19s) (51000 70%) 1.1423\n",
      "36m 52s (- 12m 17s) (54000 75%) 1.0850\n",
      "38m 58s (- 10m 15s) (57000 79%) 1.0277\n",
      "41m 1s (- 8m 12s) (60000 83%) 1.0513\n",
      "43m 6s (- 6m 9s) (63000 87%) 1.1323\n",
      "45m 10s (- 4m 6s) (66000 91%) 1.0470\n",
      "47m 14s (- 2m 3s) (69000 95%) 1.1254\n",
      "49m 19s (- 0m 0s) (72000 100%) 1.0549\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 72000, print_every=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> switch to go tv\n",
      "= switch to go tv\n",
      "< switch to tv tv <EOS>\n",
      "\n",
      "> i'd like to watch champions hockey league\n",
      "= i'd like to watch champions hockey league\n",
      "< i'd like to watch champions hockey league <EOS>\n",
      "\n",
      "> i want to change the channel\n",
      "= i want to change the channel\n",
      "< i want to change the channel <EOS>\n",
      "\n",
      "> i want to watch a tennis game\n",
      "= i want to watch a tennis game\n",
      "< i want to watch a tennis game <EOS>\n",
      "\n",
      "> the weather report please\n",
      "= the weather report please\n",
      "< the weather report please <EOS>\n",
      "\n",
      "> i'd like to know if it is warm outside\n",
      "= i'd like to know if it is warm outside\n",
      "< i'd like to know if it is warm outside <EOS>\n",
      "\n",
      "> i wanna switch to radio channel ninety nine\n",
      "= i wanna switch to radio channel 99\n",
      "< i wanna switch to radio channel 99 <EOS>\n",
      "\n",
      "> how is the weather in auer on thirtieth december\n",
      "= how is the weather in auer on 30.12\n",
      "< how is the weather in auer on 30.12 <EOS>\n",
      "\n",
      "> play the movie running with the devil\n",
      "= play the movie running with the devil\n",
      "< play the movie with me <EOS>\n",
      "\n",
      "> turn on device swisscom box two\n",
      "= turn on device swisscom box 2\n",
      "< turn on device swisscom box 2 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> turn on law and order criminal intent\n",
      "= turn on law and order: criminal intent\n",
      "< turn on interested and a <EOS>\n",
      "\n",
      "> i wanna watch feed\n",
      "= i wanna watch feed\n",
      "< i wanna watch serie <EOS>\n",
      "\n",
      "> weather update for sixteen fifty four in fussen\n",
      "= weather update for 16:54 in fussen\n",
      "< weather update for 16:54 in fussen <EOS>\n",
      "\n",
      "> six thousand two hundred and twenty seven\n",
      "= 6227\n",
      "< 3157 <EOS>\n",
      "\n",
      "> six thousand six hundred and seventy\n",
      "= 6670\n",
      "< 3157 <EOS>\n",
      "\n",
      "> turn on camera in the office\n",
      "= turn on camera in the office\n",
      "< turn on camera in the office <EOS>\n",
      "\n",
      "> change to radio channel eleven please\n",
      "= change to radio channel 11 please\n",
      "< change to radio channel 11 please <EOS>\n",
      "\n",
      "> one hundred and fifty four\n",
      "= 154\n",
      "< 4 <EOS>\n",
      "\n",
      "> i would like to change the radio station\n",
      "= i would like to change the radio station\n",
      "< i would like to change the radio station <EOS>\n",
      "\n",
      "> three thousand three hundred and twenty three\n",
      "= 3323\n",
      "< 23 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> change radio station\n",
      "= change radio station\n",
      "< change radio station <EOS>\n",
      "\n",
      "> turn on the q bees in the bedroom\n",
      "= turn on the q bees in the bedroom\n",
      "< turn on the q bees in the bedroom <EOS>\n",
      "\n",
      "> please search for cold comes the night\n",
      "= please search for cold comes the night\n",
      "< please search for the good at the <EOS>\n",
      "\n",
      "> activate the device outdoor\n",
      "= activate the device outdoor\n",
      "< activate the device outdoor <EOS>\n",
      "\n",
      "> two thousand two hundred\n",
      "= 2200\n",
      "< 3157 <EOS>\n",
      "\n",
      "> show me brighton and hove albion\n",
      "= show me brighton & hove albion\n",
      "< show me west & & <EOS>\n",
      "\n",
      "> turn on my switch\n",
      "= turn on my switch\n",
      "< turn on my switch <EOS>\n",
      "\n",
      "> put on tv channel nine\n",
      "= put on tv channel 9\n",
      "< put on tv channel 9 <EOS>\n",
      "\n",
      "> i want to change the station to radio channel rmc italia\n",
      "= i want to change the station to radio channel rmc italia\n",
      "< i want to change the station to radio channel radio channel <EOS>\n",
      "\n",
      "> is it raining on thirtieth march\n",
      "= is it raining on 30.3\n",
      "< is it raining on 30.3 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> six thousand eight hundred and thirteen\n",
      "= 6813\n",
      "< would <EOS>\n",
      "\n",
      "> switch to kuriakos tv\n",
      "= switch to kuriakos tv\n",
      "< switch to tv tv <EOS>\n",
      "\n",
      "> will i need an umbrella on sixteenth october\n",
      "= will i need an umbrella on 16.10\n",
      "< will i need an umbrella on 16.10 <EOS>\n",
      "\n",
      "> nine thousand six hundred and forty eight\n",
      "= 9648\n",
      "< would <EOS>\n",
      "\n",
      "> what's the weather gonna be like in zurich\n",
      "= what's the weather gonna be like in zurich\n",
      "< what's the weather gonna be like in zurich <EOS>\n",
      "\n",
      "> how is the temperature between nine oh three and twenty forty in neumarkt\n",
      "= how is the temperature between 09:03 and 20:40 in neumarkt\n",
      "< how is the temperature between 19:20 and 19:20 in neumarkt <EOS>\n",
      "\n",
      "> i need to know if it is raining\n",
      "= i need to know if it is raining\n",
      "< i need to know if it is raining <EOS>\n",
      "\n",
      "> i want to listen to something else\n",
      "= i want to listen to something else\n",
      "< i want to listen to something else <EOS>\n",
      "\n",
      "> i would like to watch annie\n",
      "= i would like to watch annie\n",
      "< i would like to watch handball <EOS>\n",
      "\n",
      "> could you give me the weather report\n",
      "= could you give me the weather report\n",
      "< could you give me the weather report <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = change to radio channel sixty please\n",
      "output = change to radio channel 60 please <EOS>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "#     showAttention(input_sentence, output_words, attentions)\n",
    "    \n",
    "evaluateAndShowAttention(\"change to radio channel sixty please\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## issue1: unkown mapping -> larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = change to radio channel forty two please\n",
      "output = change to radio channel 40 please <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"change to radio channel forty two please\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## issue2: unkown words -> GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i'd like to watch lord of the ring\n",
      "output = i'd like to watch ice the the <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"i'd like to watch lord of the ring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/s2s_70k_decoder.pkl'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    " \n",
    "def load_variable(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "\n",
    "save_variable(encoder1, 'models/s2s_70k_encoder.pkl') \n",
    "save_variable(attn_decoder1, 'models/s2s_70k_decoder.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_variable('models/s2s_70k_encoder.pkl')\n",
    "b = load_variable('models/s2s_70k_decoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> is it pouring\n",
      "= is it pouring\n",
      "< is it pouring <EOS>\n",
      "\n",
      "> do you have tennis\n",
      "= do you have tennis\n",
      "< do you have tennis <EOS>\n",
      "\n",
      "> will i be cold today\n",
      "= will i be cold today\n",
      "< will i be cold today <EOS>\n",
      "\n",
      "> four thousand nine hundred and forty nine\n",
      "= 4949\n",
      "< would <EOS>\n",
      "\n",
      "> play the movie shaun the sheep movie farmageddon\n",
      "= play the movie shaun the sheep movie: farmageddon\n",
      "< play the movie the the day after <EOS>\n",
      "\n",
      "> which temperatures can we expect in zurich\n",
      "= which temperatures can we expect in zurich\n",
      "< which temperatures can we expect in zurich <EOS>\n",
      "\n",
      "> am i going to be cold\n",
      "= am i going to be cold\n",
      "< am i going to be cold <EOS>\n",
      "\n",
      "> find comedie plus\n",
      "= find comedie !+\n",
      "< find planete + <EOS>\n",
      "\n",
      "> turn on tv channel forty\n",
      "= turn on tv channel 40\n",
      "< turn on tv channel 40 <EOS>\n",
      "\n",
      "> how warm will it get at six twenty two\n",
      "= how warm will it get at 06:22\n",
      "< how warm will it get at 06:22 <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhechensu/miniconda3/envs/pp/lib/python3.8/site-packages/torch/nn/modules/rnn.py:734: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629411241/work/aten/src/ATen/native/cudnn/RNN.cpp:1264.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
